random_seed: 0
model_name: "meta-llama/Llama-3.2-1B-Instruct"
training_data: "prompts_13_03_25_gpt-4o_filtered.jsonl"
batch_size: 32
cv_folds: 5
best_layer: 5
layers: [5, 6]
max_samples: 20
experiments_to_run:
  - null

probes:
  - name: "sklearn_probe"
    preprocessor: "mean"
    postprocessor: "sigmoid"
  - name: "pytorch_per_token_probe"
    preprocessor: "mean"
    postprocessor: "sigmoid"

best_probe:
  name: "sklearn_probe"
  preprocessor: "mean"
  postprocessor: "sigmoid"

baseline_models:
  - llama-1b
  - gemma-1b

variation_types:
  - prompt_style
  - tone
  - language
  - length

scaling_models:
  # - llama-1b
  # - llama-3b
  # - llama-8b
  - gemma-1b
  - gemma-12b
  - gemma-27b

scaling_layers:
  # - 6
  # - 14
  # - 18
  - 16
  - 22
  - 28

scaling_probe:
  name: "sklearn_probe"
  preprocessor: "mean"
  postprocessor: "sigmoid"
