# @package _global_
model_name: llama-70b
train_data: "prompts_13_03_25_gpt-4o_filtered.jsonl"
use_test_set: false
max_samples: null
experiments_to_run:
  - scaling_plot
scaling_plot:
  scaling_models:
    - llama-1b
  scaling_layers:
    - 6

  probe_spec:
    name: "pytorch_per_entry_probe_mean"
    hyperparams:
      epochs: 40
      learning_rate: 1e-4
      weight_decay: 0.01
      device: "cpu"
      batch_size: 32
