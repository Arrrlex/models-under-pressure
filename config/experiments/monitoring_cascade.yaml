# @package _global_
defaults:
  - /probe: pytorch_per_entry_probe_mean  # or any other probe type

model_names:
  - llama-70b
  - gemma-27b
  - gemma-12b
  - llama-8b
  - llama-1b
  - gemma-1b
first_baseline_model_name: llama-1b
#probe_model_name: llama-70b
probe_model_name: null
probe_layer: null
eval_datasets: ["toolace", "mt", "mts", "mask"]
train_dataset_path: training/original_doubled_unconfounded/train.jsonl
max_samples: null
batch_size: 4
compute_activations: true
compute_results: true
compute_cascade: false
plot_results: false
output_dir: data/results/monitoring_cascade
