name: last
hyperparams:
  batch_size: 16
  epochs: 200
  optimizer_args:
    lr: 5e-3
    weight_decay: 1e-3
  final_lr: 1e-4
  gradient_accumulation_steps: 4
  patience: 10
