{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Probe Exploration\n",
    "\n",
    "### Goals:\n",
    "- Train a simple linear logistic regression probe on Llama-3-7b\n",
    "    - Update Alex 19/02/25: since I'm running this on my macbook, I'll just use the 1b model \n",
    "- Understand GPU capacity - can we do inference with 70B?\n",
    "- Look at the probe activations / test set classifications\n",
    "\n",
    "### Timeline:\n",
    "- 18/02/25\n",
    "- 19/02/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alex/Development/lasr/models-under-pressure/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from models_under_pressure.probes import (\n",
    "    train_single_layer,\n",
    "    compute_accuracy,\n",
    "    create_activations,\n",
    "    LinearProbe,\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset was generated using GPT-4o. It consists of 20 examples with red things and 20 examples with green things. We hope to learn a classifier / probe for green or red objects.\n",
    "\n",
    "`Command: Generate 20 sentences about red things. Generate 20 sentences about green things. Put them in a JSON array of strings.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "X = df[\"prompt_text\"].tolist()\n",
    "y = df[\"high_stakes\"].tolist()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Get total number of samples\n",
    "n_samples = len(X)\n",
    "print(n_samples)\n",
    "\n",
    "# Generate random indices for train/test split (80/20)\n",
    "indices = np.random.permutation(n_samples)\n",
    "train_size = int(0.8 * n_samples)\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_text = [X[i] for i in indices[:train_size]]\n",
    "test_text = [X[i] for i in indices[train_size:]]\n",
    "train_labels = [y[i] for i in indices[:train_size]]\n",
    "test_labels = [y[i] for i in indices[train_size:]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Feature Inputs for the Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 0, Activation Shape: torch.Size([80, 34, 2048])\n",
      "Layer: 1, Activation Shape: torch.Size([80, 34, 2048])\n",
      "Layer: 2, Activation Shape: torch.Size([80, 34, 2048])\n",
      "Layer: 3, Activation Shape: torch.Size([80, 34, 2048])\n",
      "Layer: 4, Activation Shape: torch.Size([80, 34, 2048])\n",
      "Layer: 5, Activation Shape: torch.Size([80, 34, 2048])\n",
      "Layer: 6, Activation Shape: torch.Size([80, 34, 2048])\n",
      "Layer: 7, Activation Shape: torch.Size([80, 34, 2048])\n",
      "Layer: 8, Activation Shape: torch.Size([80, 34, 2048])\n",
      "Layer: 9, Activation Shape: torch.Size([80, 34, 2048])\n",
      "Layer: 10, Activation Shape: torch.Size([80, 34, 2048])\n",
      "Layer: 11, Activation Shape: torch.Size([80, 34, 2048])\n",
      "Layer: 12, Activation Shape: torch.Size([80, 34, 2048])\n",
      "Layer: 13, Activation Shape: torch.Size([80, 34, 2048])\n",
      "Layer: 14, Activation Shape: torch.Size([80, 34, 2048])\n",
      "Layer: 15, Activation Shape: torch.Size([80, 34, 2048])\n",
      "All activations shape: torch.Size([16, 80, 34, 2048])\n",
      "Layer: 0, Activation Shape: torch.Size([20, 33, 2048])\n",
      "Layer: 1, Activation Shape: torch.Size([20, 33, 2048])\n",
      "Layer: 2, Activation Shape: torch.Size([20, 33, 2048])\n",
      "Layer: 3, Activation Shape: torch.Size([20, 33, 2048])\n",
      "Layer: 4, Activation Shape: torch.Size([20, 33, 2048])\n",
      "Layer: 5, Activation Shape: torch.Size([20, 33, 2048])\n",
      "Layer: 6, Activation Shape: torch.Size([20, 33, 2048])\n",
      "Layer: 7, Activation Shape: torch.Size([20, 33, 2048])\n",
      "Layer: 8, Activation Shape: torch.Size([20, 33, 2048])\n",
      "Layer: 9, Activation Shape: torch.Size([20, 33, 2048])\n",
      "Layer: 10, Activation Shape: torch.Size([20, 33, 2048])\n",
      "Layer: 11, Activation Shape: torch.Size([20, 33, 2048])\n",
      "Layer: 12, Activation Shape: torch.Size([20, 33, 2048])\n",
      "Layer: 13, Activation Shape: torch.Size([20, 33, 2048])\n",
      "Layer: 14, Activation Shape: torch.Size([20, 33, 2048])\n",
      "Layer: 15, Activation Shape: torch.Size([20, 33, 2048])\n",
      "All activations shape: torch.Size([16, 20, 33, 2048])\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "# device = 'cuda:1'\n",
    "device = \"cpu\"\n",
    "\n",
    "# Load the LLaMA-3-1B model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Run the model on the train and test data, recording the activations\n",
    "\n",
    "train_acts = create_activations(\n",
    "    model=model, tokenizer=tokenizer, text=train_text, device=device\n",
    ")\n",
    "\n",
    "test_acts = create_activations(\n",
    "    model=model, tokenizer=tokenizer, text=test_text, device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Code for the Probe\n",
    "\n",
    "Use `sklearn` logistic regression classifier to learn a linear classifier on the activations from the model. We do the following:\n",
    "\n",
    "1. Create the y labels (1 for red and 0 for green)\n",
    "2. Restructure X to match sklearn (Batch_size, Embedd_dim) -> One per layer, final seq pos **TODO: Iterate in Future**  \n",
    "3. Run Logistic Regression\n",
    "4. Test on 5 test data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.85,\n",
       " 0.8,\n",
       " 0.95,\n",
       " 0.9,\n",
       " 0.95,\n",
       " 0.95,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.95,\n",
       " 0.95,\n",
       " 0.95,\n",
       " 0.95,\n",
       " 0.95]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = {\"C\": 1, \"random_state\": 42, \"fit_intercept\": False}\n",
    "\n",
    "layer_probes: list[LinearProbe] = Parallel(n_jobs=16)(\n",
    "    delayed(train_single_layer)(acts, train_labels, model_params) for acts in train_acts\n",
    ")  # type: ignore\n",
    "\n",
    "accuracies = [\n",
    "    compute_accuracy(probe, test_acts[i], test_labels)\n",
    "    for i, probe in enumerate(layer_probes)\n",
    "]\n",
    "\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 0:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.500, 0.500]\n",
      "AUC-ROC: 0.919\n",
      "\n",
      "Layer 1:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.5   0.501 0.5   0.5   0.5   0.501 0.5   0.5   0.5   0.5   0.5   0.5\n",
      " 0.5   0.5   0.5   0.501 0.5   0.5   0.5   0.5  ]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.500, 0.501]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 2:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.512 0.512 0.512 0.512 0.512 0.512 0.512 0.512 0.512 0.512 0.512 0.512\n",
      " 0.512 0.512 0.512 0.512 0.512 0.512 0.512 0.512]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.512, 0.512]\n",
      "AUC-ROC: 0.990\n",
      "\n",
      "Layer 3:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.512 0.512 0.512 0.512 0.512 0.512 0.512 0.512 0.512 0.512 0.512 0.512\n",
      " 0.512 0.512 0.512 0.512 0.512 0.512 0.512 0.512]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.512, 0.512]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 4:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.512 0.513 0.512 0.512 0.511 0.513 0.512 0.512 0.512 0.511 0.511 0.512\n",
      " 0.512 0.511 0.512 0.513 0.513 0.512 0.513 0.512]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.511, 0.513]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 5:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.512 0.513 0.512 0.512 0.511 0.513 0.513 0.513 0.512 0.511 0.511 0.511\n",
      " 0.513 0.511 0.511 0.513 0.513 0.513 0.513 0.512]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.511, 0.513]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 6:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.512 0.514 0.512 0.512 0.511 0.513 0.512 0.513 0.512 0.511 0.511 0.511\n",
      " 0.513 0.511 0.511 0.513 0.513 0.513 0.513 0.511]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.511, 0.514]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 7:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.512 0.514 0.512 0.513 0.51  0.514 0.513 0.513 0.512 0.51  0.51  0.511\n",
      " 0.513 0.511 0.511 0.514 0.514 0.513 0.514 0.511]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.510, 0.514]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 8:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.512 0.515 0.512 0.513 0.51  0.514 0.513 0.514 0.512 0.51  0.51  0.511\n",
      " 0.513 0.51  0.51  0.514 0.514 0.514 0.514 0.511]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.510, 0.515]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 9:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.512 0.515 0.512 0.513 0.51  0.514 0.513 0.514 0.513 0.51  0.51  0.511\n",
      " 0.514 0.51  0.51  0.514 0.514 0.514 0.515 0.511]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.510, 0.515]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 10:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.513 0.517 0.512 0.513 0.509 0.516 0.514 0.516 0.513 0.509 0.509 0.51\n",
      " 0.515 0.509 0.51  0.516 0.515 0.515 0.517 0.511]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.509, 0.517]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 11:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.513 0.519 0.512 0.514 0.508 0.517 0.515 0.517 0.514 0.508 0.509 0.51\n",
      " 0.516 0.509 0.51  0.518 0.516 0.516 0.518 0.511]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.508, 0.519]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 12:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.514 0.522 0.513 0.515 0.506 0.519 0.516 0.519 0.514 0.507 0.508 0.509\n",
      " 0.519 0.507 0.509 0.521 0.519 0.518 0.52  0.51 ]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.506, 0.522]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 13:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.515 0.526 0.513 0.516 0.504 0.521 0.517 0.522 0.516 0.506 0.506 0.508\n",
      " 0.521 0.506 0.508 0.525 0.521 0.52  0.523 0.509]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.504, 0.526]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 14:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.516 0.531 0.513 0.519 0.501 0.526 0.519 0.527 0.518 0.502 0.503 0.506\n",
      " 0.524 0.502 0.506 0.531 0.525 0.524 0.528 0.509]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.501, 0.531]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 15:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.519 0.543 0.512 0.522 0.494 0.533 0.522 0.535 0.522 0.497 0.498 0.504\n",
      " 0.531 0.497 0.504 0.542 0.531 0.531 0.535 0.508]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.494, 0.543]\n",
      "AUC-ROC: 1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Calculate AUC-ROC for each layer\n",
    "auc_scores = []\n",
    "for i, probe in enumerate(layer_probes):\n",
    "    # Get probability predictions for positive class\n",
    "    X = probe._preprocess_activations(test_acts[i])\n",
    "    y_proba = probe._model.predict_proba(X)[:, 1]\n",
    "\n",
    "    # Print debugging information\n",
    "    print(f\"\\nLayer {i}:\")\n",
    "    print(\"True labels:\", test_labels)\n",
    "    print(\"Predicted probabilities:\", y_proba.round(3))\n",
    "\n",
    "    # Verify we have variation in both labels and predictions\n",
    "    print(f\"Unique true labels: {np.unique(test_labels)}\")\n",
    "    print(f\"Prediction range: [{y_proba.min():.3f}, {y_proba.max():.8f}]\")\n",
    "\n",
    "    # Calculate AUC-ROC\n",
    "    try:\n",
    "        auc = roc_auc_score(test_labels, y_proba)\n",
    "        auc_scores.append(auc)\n",
    "        print(f\"AUC-ROC: {auc:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating AUC-ROC: {e}\")\n",
    "        auc_scores.append(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 5 Predictions vs True Labels:\n",
      "    True Label  Predicted Probability\n",
      "1            1                  0.513\n",
      "7            1                  0.513\n",
      "6            1                  0.513\n",
      "5            1                  0.513\n",
      "16           1                  0.513\n",
      "17           1                  0.513\n",
      "15           1                  0.513\n",
      "18           1                  0.513\n",
      "12           1                  0.513\n",
      "3            1                  0.512\n",
      "0            0                  0.512\n",
      "2            0                  0.512\n",
      "8            1                  0.512\n",
      "19           0                  0.512\n",
      "9            0                  0.511\n",
      "4            0                  0.511\n",
      "11           0                  0.511\n",
      "10           0                  0.511\n",
      "14           0                  0.511\n",
      "13           0                  0.511\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for layer 5\n",
    "layer_5_probe = layer_probes[5]\n",
    "X = layer_5_probe._preprocess_activations(test_acts[5])\n",
    "y_proba = layer_5_probe._model.predict_proba(X)[:, 1]\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(\n",
    "    {\"True Label\": test_labels, \"Predicted Probability\": y_proba}\n",
    ").round(3)\n",
    "\n",
    "# Sort by predicted probability for easier analysis\n",
    "results_df = results_df.sort_values(\"Predicted Probability\", ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nLayer 5 Predictions vs True Labels:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
