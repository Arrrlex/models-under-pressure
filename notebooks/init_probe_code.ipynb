{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Probe Exploration\n",
    "\n",
    "### Goals:\n",
    "- [x] Train a simple linear logistic regression probe on Llama-3-7b\n",
    "    - Update Alex 19/02/25: since I'm running this on my macbook, I'll just use the 1b model \n",
    "- Understand GPU capacity - can we do inference with 70B?\n",
    "- Look at the probe activations / test set classifications\n",
    "\n",
    "### Todos\n",
    "\n",
    "- [ ] Add some logging to training\n",
    "\n",
    "### Lessons\n",
    "- Taking the mean over seq_pos seems to work (much) better than just using the last pos\n",
    "\n",
    "### Timeline:\n",
    "- 18/02/25\n",
    "- 19/02/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucabwjn/models-under-pressure/.venv/lib64/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from models_under_pressure.probes import (\n",
    "    train_single_layer,\n",
    "    compute_accuracy,\n",
    "    create_activations,\n",
    "    LinearProbe,\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path(\".\").resolve().parent\n",
    "cache_dir = '/scratch/ucabwjn/.cache'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset was generated using GPT-4o. It consists of 20 examples with red things and 20 examples with green things. We hope to learn a classifier / probe for green or red objects.\n",
    "\n",
    "`Command: Generate 20 sentences about red things. Generate 20 sentences about green things. Put them in a JSON array of strings.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(project_root / \"temp_data/dataset_19_feb.csv\")\n",
    "\n",
    "X = df[\"prompt_text\"].tolist()\n",
    "y = df[\"high_stakes\"].tolist()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Get total number of samples\n",
    "n_samples = len(X)\n",
    "print(n_samples)\n",
    "\n",
    "# Generate random indices for train/test split (80/20)\n",
    "indices = np.random.permutation(n_samples)\n",
    "train_size = int(0.8 * n_samples)\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_text = [X[i] for i in indices[:train_size]]\n",
    "test_text = [X[i] for i in indices[train_size:]]\n",
    "train_labels = [y[i] for i in indices[:train_size]]\n",
    "test_labels = [y[i] for i in indices[train_size:]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Feature Inputs for the Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:117] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 33554432 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load the LLaMA-3-1B model and tokenizer\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/models-under-pressure/.venv/lib64/python3.12/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/models-under-pressure/.venv/lib64/python3.12/site-packages/transformers/modeling_utils.py:262\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m~/models-under-pressure/.venv/lib64/python3.12/site-packages/transformers/modeling_utils.py:4185\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4179\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_autoset_attn_implementation(\n\u001b[1;32m   4180\u001b[0m         config, use_flash_attention_2\u001b[38;5;241m=\u001b[39muse_flash_attention_2, torch_dtype\u001b[38;5;241m=\u001b[39mtorch_dtype, device_map\u001b[38;5;241m=\u001b[39mdevice_map\n\u001b[1;32m   4181\u001b[0m     )\n\u001b[1;32m   4183\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[1;32m   4184\u001b[0m     \u001b[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001b[39;00m\n\u001b[0;32m-> 4185\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4187\u001b[0m \u001b[38;5;66;03m# make sure we use the model's config since the __init__ call might have copied it\u001b[39;00m\n\u001b[1;32m   4188\u001b[0m config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n",
      "File \u001b[0;32m~/models-under-pressure/.venv/lib64/python3.12/site-packages/transformers/models/llama/modeling_llama.py:759\u001b[0m, in \u001b[0;36mLlamaForCausalLM.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config):\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[0;32m--> 759\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[1;32m    761\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(config\u001b[38;5;241m.\u001b[39mhidden_size, config\u001b[38;5;241m.\u001b[39mvocab_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/models-under-pressure/.venv/lib64/python3.12/site-packages/transformers/models/llama/modeling_llama.py:503\u001b[0m, in \u001b[0;36mLlamaModel.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(config\u001b[38;5;241m.\u001b[39mvocab_size, config\u001b[38;5;241m.\u001b[39mhidden_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx)\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[0;32m--> 503\u001b[0m     [\u001b[43mLlamaDecoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_hidden_layers)]\n\u001b[1;32m    504\u001b[0m )\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m LlamaRMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_emb \u001b[38;5;241m=\u001b[39m LlamaRotaryEmbedding(config\u001b[38;5;241m=\u001b[39mconfig)\n",
      "File \u001b[0;32m~/models-under-pressure/.venv/lib64/python3.12/site-packages/transformers/models/llama/modeling_llama.py:313\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.__init__\u001b[0;34m(self, config, layer_idx)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mhidden_size\n\u001b[0;32m--> 313\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp \u001b[38;5;241m=\u001b[39m LlamaMLP(config)\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm \u001b[38;5;241m=\u001b[39m LlamaRMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[0;32m~/models-under-pressure/.venv/lib64/python3.12/site-packages/transformers/models/llama/modeling_llama.py:248\u001b[0m, in \u001b[0;36mLlamaAttention.__init__\u001b[0;34m(self, config, layer_idx)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_causal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\n\u001b[1;32m    246\u001b[0m     config\u001b[38;5;241m.\u001b[39mhidden_size, config\u001b[38;5;241m.\u001b[39mnum_attention_heads \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim, bias\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mattention_bias\n\u001b[1;32m    247\u001b[0m )\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_key_value_heads\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_bias\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\n\u001b[1;32m    252\u001b[0m     config\u001b[38;5;241m.\u001b[39mhidden_size, config\u001b[38;5;241m.\u001b[39mnum_key_value_heads \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim, bias\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mattention_bias\n\u001b[1;32m    253\u001b[0m )\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mo_proj \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\n\u001b[1;32m    255\u001b[0m     config\u001b[38;5;241m.\u001b[39mnum_attention_heads \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim, config\u001b[38;5;241m.\u001b[39mhidden_size, bias\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mattention_bias\n\u001b[1;32m    256\u001b[0m )\n",
      "File \u001b[0;32m~/models-under-pressure/.venv/lib64/python3.12/site-packages/torch/nn/modules/linear.py:98\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features \u001b[38;5;241m=\u001b[39m in_features\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features \u001b[38;5;241m=\u001b[39m out_features\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:117] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 33554432 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "model_name = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "\n",
    "# device = 'cuda:1'\n",
    "device = \"cuda:3\"\n",
    "\n",
    "# Load the LLaMA-3-1B model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=cache_dir).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Run the model on the train and test data, recording the activations\n",
    "\n",
    "train_acts = create_activations(\n",
    "    model=model, tokenizer=tokenizer, text=train_text, device=device\n",
    ")\n",
    "\n",
    "test_acts = create_activations(\n",
    "    model=model, tokenizer=tokenizer, text=test_text, device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Code for the Probe\n",
    "\n",
    "Use `sklearn` logistic regression classifier to learn a linear classifier on the activations from the model. We do the following:\n",
    "\n",
    "1. Create the y labels (1 for red and 0 for green)\n",
    "2. Restructure X to match sklearn (Batch_size, Embedd_dim) -> One per layer, final seq pos **TODO: Iterate in Future**  \n",
    "3. Run Logistic Regression\n",
    "4. Test on 5 test data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.95,\n",
       " 0.95,\n",
       " 1.0,\n",
       " 0.95,\n",
       " 1.0,\n",
       " 0.95,\n",
       " 0.95,\n",
       " 0.9,\n",
       " 0.95,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.95,\n",
       " 0.95,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = {\"C\": 1, \"random_state\": 42, \"fit_intercept\": False}\n",
    "\n",
    "layer_probes: list[LinearProbe] = Parallel(n_jobs=16)(\n",
    "    delayed(train_single_layer)(acts, train_labels, model_params) for acts in train_acts\n",
    ")  # type: ignore\n",
    "\n",
    "accuracies = [\n",
    "    compute_accuracy(probe, test_acts[i], test_labels)\n",
    "    for i, probe in enumerate(layer_probes)\n",
    "]\n",
    "\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 0:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.972 1.    0.478 0.998 0.001 1.    0.993 0.988 0.992 0.002 0.    0.\n",
      " 0.993 0.001 0.085 1.    0.987 0.998 0.999 0.03 ]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99997967]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 1:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.925 1.    0.157 0.999 0.    1.    0.999 0.996 0.999 0.004 0.001 0.003\n",
      " 0.999 0.    0.037 1.    0.999 0.999 1.    0.014]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999683]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 2:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.272 1.    0.012 0.896 0.    1.    0.982 0.979 0.965 0.    0.001 0.\n",
      " 0.976 0.    0.018 1.    0.998 0.993 0.999 0.   ]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99996137]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 3:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.731 1.    0.298 0.989 0.    1.    0.986 0.993 0.952 0.    0.002 0.001\n",
      " 0.998 0.    0.03  1.    0.999 0.997 1.    0.003]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999171]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 4:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.244 1.    0.356 0.999 0.    1.    0.998 0.998 0.964 0.    0.001 0.005\n",
      " 0.998 0.    0.008 1.    1.    0.999 1.    0.009]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999637]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 5:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.329 1.    0.515 0.998 0.    1.    0.997 0.998 0.956 0.    0.    0.001\n",
      " 0.995 0.    0.003 1.    1.    0.999 1.    0.003]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99998799]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 6:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.32  1.    0.804 0.992 0.    1.    0.992 0.998 0.884 0.    0.    0.002\n",
      " 0.998 0.    0.004 1.    1.    0.999 1.    0.004]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999468]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 7:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.634 1.    0.857 0.996 0.    1.    0.977 0.999 0.908 0.    0.    0.004\n",
      " 0.995 0.001 0.005 1.    1.    0.998 1.    0.008]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99997908]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 8:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.212 1.    0.819 0.995 0.    1.    0.984 0.998 0.905 0.    0.    0.003\n",
      " 0.995 0.002 0.008 1.    1.    0.999 1.    0.011]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99998038]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 9:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.598 1.    0.766 0.996 0.    1.    0.98  0.999 0.972 0.    0.    0.023\n",
      " 0.997 0.002 0.018 1.    1.    0.999 1.    0.015]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999012]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 10:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.54  1.    0.681 0.998 0.    1.    0.993 0.999 0.951 0.    0.    0.01\n",
      " 0.999 0.    0.019 1.    1.    0.999 1.    0.028]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999502]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 11:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.389 1.    0.571 0.996 0.    1.    0.995 0.998 0.923 0.    0.    0.007\n",
      " 0.999 0.    0.023 1.    1.    0.999 1.    0.013]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999636]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 12:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.339 1.    0.502 0.992 0.    1.    0.986 1.    0.934 0.    0.    0.01\n",
      " 0.998 0.    0.018 1.    1.    0.999 1.    0.008]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999650]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 13:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.319 1.    0.407 0.989 0.    1.    0.99  1.    0.936 0.    0.    0.008\n",
      " 0.999 0.    0.026 1.    1.    0.999 1.    0.005]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999850]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 14:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.354 1.    0.253 0.998 0.    1.    0.99  1.    0.984 0.    0.    0.003\n",
      " 0.998 0.    0.025 1.    1.    0.999 1.    0.004]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999811]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 15:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.399 1.    0.138 0.999 0.    1.    0.99  1.    0.991 0.    0.    0.006\n",
      " 0.999 0.    0.024 1.    1.    1.    1.    0.002]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999957]\n",
      "AUC-ROC: 1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Calculate AUC-ROC for each layer\n",
    "auc_scores = []\n",
    "for i, probe in enumerate(layer_probes):\n",
    "    # Get probability predictions for positive class\n",
    "    X = probe._preprocess_activations(test_acts[i])\n",
    "    y_proba = probe._model.predict_proba(X)[:, 1]\n",
    "\n",
    "    # Print debugging information\n",
    "    print(f\"\\nLayer {i}:\")\n",
    "    print(\"True labels:\", test_labels)\n",
    "    print(\"Predicted probabilities:\", y_proba.round(3))\n",
    "\n",
    "    # Verify we have variation in both labels and predictions\n",
    "    print(f\"Unique true labels: {np.unique(test_labels)}\")\n",
    "    print(f\"Prediction range: [{y_proba.min():.3f}, {y_proba.max():.8f}]\")\n",
    "\n",
    "    # Calculate AUC-ROC\n",
    "    try:\n",
    "        auc = roc_auc_score(test_labels, y_proba)\n",
    "        auc_scores.append(auc)\n",
    "        print(f\"AUC-ROC: {auc:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating AUC-ROC: {e}\")\n",
    "        auc_scores.append(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 5 Predictions vs True Labels:\n",
      "    True Label  Predicted Probability\n",
      "1            1                  1.000\n",
      "16           1                  1.000\n",
      "18           1                  1.000\n",
      "5            1                  1.000\n",
      "15           1                  1.000\n",
      "17           1                  0.999\n",
      "3            1                  0.998\n",
      "7            1                  0.998\n",
      "6            1                  0.997\n",
      "12           1                  0.995\n",
      "8            1                  0.956\n",
      "2            0                  0.515\n",
      "0            0                  0.329\n",
      "14           0                  0.003\n",
      "19           0                  0.003\n",
      "11           0                  0.001\n",
      "10           0                  0.000\n",
      "9            0                  0.000\n",
      "4            0                  0.000\n",
      "13           0                  0.000\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for layer 5\n",
    "layer_5_probe = layer_probes[5]\n",
    "X = layer_5_probe._preprocess_activations(test_acts[5])\n",
    "y_proba = layer_5_probe._model.predict_proba(X)[:, 1]\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(\n",
    "    {\"True Label\": test_labels, \"Predicted Probability\": y_proba}\n",
    ").round(3)\n",
    "\n",
    "# Sort by predicted probability for easier analysis\n",
    "results_df = results_df.sort_values(\"Predicted Probability\", ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nLayer 5 Predictions vs True Labels:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
