{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Probe Exploration\n",
    "\n",
    "### Goals:\n",
    "- Train a simple linear logistic regression probe on Llama-3-7b\n",
    "- Understand GPU capacity - can we do inference with 70B?\n",
    "- Look at the probe activations / test set classifications\n",
    "\n",
    "### Timeline:\n",
    "- 18/02/25\n",
    "- 19/02/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from jaxtyping import Float\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "model_name = 'meta-llama/Llama-3.3-70B-Instruct'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset was generated using GPT-4o. It consists of 20 examples with red things and 20 examples with green things. We hope to learn a classifier / probe for green or red objects.\n",
    "\n",
    "`Command: Generate 20 sentences about red things. Generate 20 sentences about green things. Put them in a JSON array of strings.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loading:\n",
    "text = [\n",
    "  \"The bright red apple hung low on the tree, ready to be picked.\",\n",
    "  \"A red sports car sped past, leaving a trail of dust behind.\",\n",
    "  \"The firefighter's uniform had reflective red stripes for visibility.\",\n",
    "  \"She wore a deep red dress that caught everyone's attention.\",\n",
    "  \"The red rose symbolized love and passion.\",\n",
    "  \"Tomatoes ripened under the sun, turning a rich shade of red.\",\n",
    "  \"The cardinal perched on the fence, its red feathers vibrant against the snow.\",\n",
    "  \"His face turned red with embarrassment after tripping on stage.\",\n",
    "  \"The sunset painted the sky in hues of red and orange.\",\n",
    "  \"Red chili peppers added a spicy kick to the dish.\",\n",
    "  \"The warning sign was painted bright red for safety reasons.\",\n",
    "  \"Her lipstick was a bold shade of red.\",\n",
    "  \"The red balloon floated away into the sky.\",\n",
    "  \"Blood is naturally red due to the presence of iron in hemoglobin.\",\n",
    "  \"Strawberries are at their sweetest when they turn fully red.\",\n",
    "  \"The red fire hydrant stood at the corner of the street.\",\n",
    "  \"Maple leaves turn a brilliant red in the autumn.\",\n",
    "  \"A red velvet cake is a delicious dessert with a hint of cocoa.\",\n",
    "  \"The ladybug crawled across the leaf, its red shell dotted with black spots.\",\n",
    "  \"Santa Claus is always dressed in his iconic red suit.\",\n",
    "  \"The fresh green grass covered the rolling hills.\",\n",
    "  \"A green traffic light signaled the cars to move forward.\",\n",
    "  \"Emeralds are precious gems with a deep green color.\",\n",
    "  \"The frog leaped into the pond, blending in with the green lily pads.\",\n",
    "  \"Spinach is a nutritious green vegetable rich in iron.\",\n",
    "  \"The soccer field was painted bright green for the championship game.\",\n",
    "  \"A bright green parrot perched on the branch, mimicking voices.\",\n",
    "  \"The cucumber felt cool and crisp in her hands.\",\n",
    "  \"The lush green rainforest was teeming with wildlife.\",\n",
    "  \"She wore a green jade bracelet that shimmered under the light.\",\n",
    "  \"Green tea is known for its numerous health benefits.\",\n",
    "  \"The traffic sign was painted green to indicate an exit route.\",\n",
    "  \"The chameleon changed its color to blend with the green leaves.\",\n",
    "  \"The avocado's skin turned dark green when fully ripe.\",\n",
    "  \"His green eyes sparkled in the sunlight.\",\n",
    "  \"The turtle slowly crawled across the green moss-covered rock.\",\n",
    "  \"The neon green sign stood out in the dimly lit alley.\",\n",
    "  \"Green grapes are sweet and slightly tangy when ripe.\",\n",
    "  \"The Christmas tree stood tall, covered in green pine needles.\",\n",
    "  \"The four-leaf clover is a rare green plant that symbolizes luck.\"\n",
    "]\n",
    "\n",
    "test_text = [\n",
    "  \"The red kite soared high above the open field.\",\n",
    "  \"A juicy red watermelon slice is perfect for a hot summer day.\",\n",
    "  \"The brick house had a classic red chimney that stood out against the sky.\",\n",
    "  \"The green lizard basked in the sun on a warm rock.\",\n",
    "  \"She decorated her room with green fairy lights for a cozy atmosphere.\"\n",
    "] \n",
    "test_labels = [1, 1, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Feature Inputs for the Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 0, Activation Shape: torch.Size([40, 18, 2048])\n",
      "Layer: 1, Activation Shape: torch.Size([40, 18, 2048])\n",
      "Layer: 2, Activation Shape: torch.Size([40, 18, 2048])\n",
      "Layer: 3, Activation Shape: torch.Size([40, 18, 2048])\n",
      "Layer: 4, Activation Shape: torch.Size([40, 18, 2048])\n",
      "Layer: 5, Activation Shape: torch.Size([40, 18, 2048])\n",
      "Layer: 6, Activation Shape: torch.Size([40, 18, 2048])\n",
      "Layer: 7, Activation Shape: torch.Size([40, 18, 2048])\n",
      "Layer: 8, Activation Shape: torch.Size([40, 18, 2048])\n",
      "Layer: 9, Activation Shape: torch.Size([40, 18, 2048])\n",
      "Layer: 10, Activation Shape: torch.Size([40, 18, 2048])\n",
      "Layer: 11, Activation Shape: torch.Size([40, 18, 2048])\n",
      "Layer: 12, Activation Shape: torch.Size([40, 18, 2048])\n",
      "Layer: 13, Activation Shape: torch.Size([40, 18, 2048])\n",
      "Layer: 14, Activation Shape: torch.Size([40, 18, 2048])\n",
      "Layer: 15, Activation Shape: torch.Size([40, 18, 2048])\n",
      "All activations shape: torch.Size([16, 40, 18, 2048])\n",
      "Layer: 0, Activation Shape: torch.Size([5, 16, 2048])\n",
      "Layer: 1, Activation Shape: torch.Size([5, 16, 2048])\n",
      "Layer: 2, Activation Shape: torch.Size([5, 16, 2048])\n",
      "Layer: 3, Activation Shape: torch.Size([5, 16, 2048])\n",
      "Layer: 4, Activation Shape: torch.Size([5, 16, 2048])\n",
      "Layer: 5, Activation Shape: torch.Size([5, 16, 2048])\n",
      "Layer: 6, Activation Shape: torch.Size([5, 16, 2048])\n",
      "Layer: 7, Activation Shape: torch.Size([5, 16, 2048])\n",
      "Layer: 8, Activation Shape: torch.Size([5, 16, 2048])\n",
      "Layer: 9, Activation Shape: torch.Size([5, 16, 2048])\n",
      "Layer: 10, Activation Shape: torch.Size([5, 16, 2048])\n",
      "Layer: 11, Activation Shape: torch.Size([5, 16, 2048])\n",
      "Layer: 12, Activation Shape: torch.Size([5, 16, 2048])\n",
      "Layer: 13, Activation Shape: torch.Size([5, 16, 2048])\n",
      "Layer: 14, Activation Shape: torch.Size([5, 16, 2048])\n",
      "Layer: 15, Activation Shape: torch.Size([5, 16, 2048])\n",
      "All activations shape: torch.Size([16, 5, 16, 2048])\n"
     ]
    }
   ],
   "source": [
    "# Load the LLaMA-3-1B model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "@torch.no_grad()\n",
    "def create_activations(text:list[str]) -> Float[torch.Tensor, \"layers batch_size seq_len embed_dim\"]:\n",
    "\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True,\n",
    "                   padding=True, max_length=1028)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Dictionary to store residual activations\n",
    "    activations = []\n",
    "\n",
    "    # Hook function to capture residual activations before layernorm\n",
    "    def hook_fn(module, input, output):\n",
    "        activations.append(input[0].detach().cpu())  # Store the residual connection\n",
    "\n",
    "    # Register hooks on each transformer block (LLaMA layers)\n",
    "    hooks = []\n",
    "    for i, layer in enumerate(model.model.layers):  # LLaMA uses model.model.layers\n",
    "        hook = layer.input_layernorm.register_forward_hook(hook_fn)  # Pre-attention residual\n",
    "        hooks.append(hook)\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        _ = model(**inputs)\n",
    "\n",
    "    # Remove hooks after capturing activations\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "    # Print stored activations\n",
    "    for i, act in enumerate(activations):\n",
    "        print(f\"Layer: {i}, Activation Shape: {act.shape}\")\n",
    "\n",
    "    all_acts = torch.stack(activations)\n",
    "    print('All activations shape:', all_acts.shape)\n",
    "\n",
    "    return all_acts.cpu()\n",
    "\n",
    "train_acts = create_activations(text)\n",
    "test_acts = create_activations(test_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Code for the Probe\n",
    "\n",
    "Use `sklearn` logistic regression classifier to learn a linear classifier on the activations from the model. We do the following:\n",
    "\n",
    "1. Create the y labels (1 for red and 0 for green)\n",
    "2. Restructure X to match sklearn (Batch_size, Embedd_dim) -> One per layer, final seq pos **TODO: Iterate in Future**  \n",
    "3. Run Logistic Regression\n",
    "4. Test on 5 test data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.shape=(40,)\n"
     ]
    }
   ],
   "source": [
    "labels = np.concatenate([np.ones(20), np.zeros(20)])\n",
    "print(f'{labels.shape=}')\n",
    "\n",
    "# Select the last sequence position activations:\n",
    "selected_train_acts = train_acts[:, :, -1, :]\n",
    "\n",
    "# Define parallel fit function:\n",
    "def train_logistic_regression(activations: Float[np.ndarray, \"batch_size embedd_dim\"],\n",
    "                            labels: Float[np.ndarray, \"batch_size\"], layer_num:int) -> tuple[LogisticRegression, float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Train a logistic regression model on the residual activations of the LLaMA model. Class designed for parallel training with joblib\n",
    "    \"\"\"   \n",
    "    \n",
    "    assert activations.shape == (40, 2048), f'Activations shape is not correct dim: {activations.shape}'\n",
    "\n",
    "    # Train a logistic regression model\n",
    "    model = LogisticRegression(C = 1e-3, random_state=42, fit_intercept=False)\n",
    "    model.fit(activations, labels)\n",
    "\n",
    "    pred_labels = model.predict(test_acts[layer_num, :, -1, :])\n",
    "    test_acc = (pred_labels == test_labels).mean()\n",
    "\n",
    "    return model, test_acc, pred_labels\n",
    "\n",
    "layer_models = Parallel(n_jobs=16)(delayed(train_logistic_regression)(act, labels, i) for i, act in enumerate(selected_train_acts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(LogisticRegression(C=0.001, fit_intercept=False, random_state=42),\n",
       "  0.4,\n",
       "  array([1., 1., 0., 1., 1.])),\n",
       " (LogisticRegression(C=0.001, fit_intercept=False, random_state=42),\n",
       "  0.4,\n",
       "  array([1., 1., 0., 1., 1.])),\n",
       " (LogisticRegression(C=0.001, fit_intercept=False, random_state=42),\n",
       "  0.4,\n",
       "  array([1., 1., 0., 1., 1.])),\n",
       " (LogisticRegression(C=0.001, fit_intercept=False, random_state=42),\n",
       "  0.4,\n",
       "  array([1., 1., 0., 1., 1.])),\n",
       " (LogisticRegression(C=0.001, fit_intercept=False, random_state=42),\n",
       "  0.4,\n",
       "  array([1., 1., 0., 1., 1.])),\n",
       " (LogisticRegression(C=0.001, fit_intercept=False, random_state=42),\n",
       "  0.4,\n",
       "  array([1., 1., 0., 1., 1.])),\n",
       " (LogisticRegression(C=0.001, fit_intercept=False, random_state=42),\n",
       "  0.4,\n",
       "  array([1., 1., 0., 1., 1.])),\n",
       " (LogisticRegression(C=0.001, fit_intercept=False, random_state=42),\n",
       "  0.4,\n",
       "  array([1., 1., 0., 1., 1.])),\n",
       " (LogisticRegression(C=0.001, fit_intercept=False, random_state=42),\n",
       "  0.4,\n",
       "  array([1., 1., 0., 1., 1.])),\n",
       " (LogisticRegression(C=0.001, fit_intercept=False, random_state=42),\n",
       "  0.4,\n",
       "  array([1., 1., 0., 1., 1.])),\n",
       " (LogisticRegression(C=0.001, fit_intercept=False, random_state=42),\n",
       "  0.4,\n",
       "  array([1., 1., 0., 1., 1.])),\n",
       " (LogisticRegression(C=0.001, fit_intercept=False, random_state=42),\n",
       "  0.4,\n",
       "  array([1., 1., 0., 1., 1.])),\n",
       " (LogisticRegression(C=0.001, fit_intercept=False, random_state=42),\n",
       "  0.4,\n",
       "  array([1., 1., 0., 1., 1.])),\n",
       " (LogisticRegression(C=0.001, fit_intercept=False, random_state=42),\n",
       "  0.4,\n",
       "  array([1., 1., 0., 1., 1.])),\n",
       " (LogisticRegression(C=0.001, fit_intercept=False, random_state=42),\n",
       "  0.4,\n",
       "  array([1., 1., 0., 1., 1.])),\n",
       " (LogisticRegression(C=0.001, fit_intercept=False, random_state=42),\n",
       "  0.4,\n",
       "  array([1., 1., 0., 1., 1.]))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
