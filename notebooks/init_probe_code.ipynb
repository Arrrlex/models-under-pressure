{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Probe Exploration\n",
    "\n",
    "### Goals:\n",
    "- [x] Train a simple linear logistic regression probe on Llama-3-7b\n",
    "    - Update Alex 19/02/25: since I'm running this on my macbook, I'll just use the 1b model \n",
    "- Understand GPU capacity - can we do inference with 70B?\n",
    "- Look at the probe activations / test set classifications\n",
    "\n",
    "### Todos\n",
    "\n",
    "- [ ] Add some logging to training\n",
    "\n",
    "### Lessons\n",
    "- Taking the mean over seq_pos seems to work (much) better than just using the last pos\n",
    "\n",
    "### Timeline:\n",
    "- 18/02/25\n",
    "- 19/02/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucabwjn/models-under-pressure/.venv/lib64/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from models_under_pressure.probes import (\n",
    "    train_single_layer,\n",
    "    compute_accuracy,\n",
    "    create_activations,\n",
    "    LinearProbe,\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path(\".\").resolve().parent\n",
    "cache_dir = '/scratch/ucabwjn/.cache'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset was generated using GPT-4o. It consists of 20 examples with red things and 20 examples with green things. We hope to learn a classifier / probe for green or red objects.\n",
    "\n",
    "`Command: Generate 20 sentences about red things. Generate 20 sentences about green things. Put them in a JSON array of strings.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(project_root / \"temp_data/dataset_19_feb.csv\")\n",
    "\n",
    "X = df[\"prompt_text\"].tolist()\n",
    "y = df[\"high_stakes\"].tolist()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Get total number of samples\n",
    "n_samples = len(X)\n",
    "print(n_samples)\n",
    "\n",
    "# Generate random indices for train/test split (80/20)\n",
    "indices = np.random.permutation(n_samples)\n",
    "train_size = int(0.8 * n_samples)\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_text = [X[i] for i in indices[:train_size]]\n",
    "test_text = [X[i] for i in indices[train_size:]]\n",
    "train_labels = [y[i] for i in indices[:train_size]]\n",
    "test_labels = [y[i] for i in indices[train_size:]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Feature Inputs for the Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 30/30 [02:47<00:00,  5.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 0, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 1, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 2, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 3, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 4, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 5, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 6, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 7, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 8, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 9, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 10, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 11, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 12, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 13, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 14, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 15, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 16, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 17, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 18, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 19, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 20, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 21, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 22, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 23, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 24, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 25, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 26, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 27, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 28, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 29, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 30, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 31, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 32, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 33, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 34, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 35, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 36, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 37, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 38, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 39, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 40, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 41, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 42, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 43, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 44, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 45, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 46, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 47, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 48, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 49, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 50, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 51, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 52, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 53, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 54, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 55, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 56, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 57, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 58, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 59, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 60, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 61, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 62, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 63, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 64, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 65, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 66, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 67, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 68, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 69, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 70, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 71, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 72, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 73, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 74, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 75, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 76, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 77, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 78, Activation Shape: torch.Size([320, 36, 8192])\n",
      "Layer: 79, Activation Shape: torch.Size([320, 36, 8192])\n",
      "All activations shape: torch.Size([80, 320, 36, 8192])\n",
      "Layer: 0, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 1, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 2, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 3, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 4, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 5, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 6, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 7, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 8, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 9, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 10, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 11, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 12, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 13, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 14, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 15, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 16, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 17, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 18, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 19, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 20, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 21, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 22, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 23, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 24, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 25, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 26, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 27, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 28, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 29, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 30, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 31, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 32, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 33, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 34, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 35, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 36, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 37, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 38, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 39, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 40, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 41, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 42, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 43, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 44, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 45, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 46, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 47, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 48, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 49, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 50, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 51, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 52, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 53, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 54, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 55, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 56, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 57, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 58, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 59, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 60, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 61, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 62, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 63, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 64, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 65, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 66, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 67, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 68, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 69, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 70, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 71, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 72, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 73, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 74, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 75, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 76, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 77, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 78, Activation Shape: torch.Size([80, 34, 8192])\n",
      "Layer: 79, Activation Shape: torch.Size([80, 34, 8192])\n",
      "All activations shape: torch.Size([80, 80, 34, 8192])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "model_name = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "\n",
    "# device = 'cuda:1'\n",
    "device = \"cuda:3\"\n",
    "\n",
    "# Load the LLaMA-3-1B model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                             device_map=\"auto\",\n",
    "                                             max_memory={0: \"80GB\", 1: \"80GB\"},\n",
    "                                             torch_dtype=torch.float16,\n",
    "                                             cache_dir=cache_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Run the model on the train and test data, recording the activations\n",
    "\n",
    "train_acts = create_activations(\n",
    "    model=model, tokenizer=tokenizer, text=train_text, device=device\n",
    ")\n",
    "\n",
    "test_acts = create_activations(\n",
    "    model=model, tokenizer=tokenizer, text=test_text, device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Code for the Probe\n",
    "\n",
    "Use `sklearn` logistic regression classifier to learn a linear classifier on the activations from the model. We do the following:\n",
    "\n",
    "1. Create the y labels (1 for red and 0 for green)\n",
    "2. Restructure X to match sklearn (Batch_size, Embedd_dim) -> One per layer, final seq pos **TODO: Iterate in Future**  \n",
    "3. Run Logistic Regression\n",
    "4. Test on 5 test data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.95,\n",
       " 0.95,\n",
       " 1.0,\n",
       " 0.95,\n",
       " 1.0,\n",
       " 0.95,\n",
       " 0.95,\n",
       " 0.9,\n",
       " 0.95,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.95,\n",
       " 0.95,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = {\"C\": 1, \"random_state\": 42, \"fit_intercept\": False}\n",
    "\n",
    "layer_probes: list[LinearProbe] = Parallel(n_jobs=16)(\n",
    "    delayed(train_single_layer)(acts, train_labels, model_params) for acts in train_acts\n",
    ")  # type: ignore\n",
    "\n",
    "accuracies = [\n",
    "    compute_accuracy(probe, test_acts[i], test_labels)\n",
    "    for i, probe in enumerate(layer_probes)\n",
    "]\n",
    "\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 0:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.972 1.    0.478 0.998 0.001 1.    0.993 0.988 0.992 0.002 0.    0.\n",
      " 0.993 0.001 0.085 1.    0.987 0.998 0.999 0.03 ]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99997967]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 1:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.925 1.    0.157 0.999 0.    1.    0.999 0.996 0.999 0.004 0.001 0.003\n",
      " 0.999 0.    0.037 1.    0.999 0.999 1.    0.014]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999683]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 2:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.272 1.    0.012 0.896 0.    1.    0.982 0.979 0.965 0.    0.001 0.\n",
      " 0.976 0.    0.018 1.    0.998 0.993 0.999 0.   ]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99996137]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 3:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.731 1.    0.298 0.989 0.    1.    0.986 0.993 0.952 0.    0.002 0.001\n",
      " 0.998 0.    0.03  1.    0.999 0.997 1.    0.003]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999171]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 4:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.244 1.    0.356 0.999 0.    1.    0.998 0.998 0.964 0.    0.001 0.005\n",
      " 0.998 0.    0.008 1.    1.    0.999 1.    0.009]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999637]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 5:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.329 1.    0.515 0.998 0.    1.    0.997 0.998 0.956 0.    0.    0.001\n",
      " 0.995 0.    0.003 1.    1.    0.999 1.    0.003]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99998799]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 6:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.32  1.    0.804 0.992 0.    1.    0.992 0.998 0.884 0.    0.    0.002\n",
      " 0.998 0.    0.004 1.    1.    0.999 1.    0.004]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999468]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 7:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.634 1.    0.857 0.996 0.    1.    0.977 0.999 0.908 0.    0.    0.004\n",
      " 0.995 0.001 0.005 1.    1.    0.998 1.    0.008]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99997908]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 8:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.212 1.    0.819 0.995 0.    1.    0.984 0.998 0.905 0.    0.    0.003\n",
      " 0.995 0.002 0.008 1.    1.    0.999 1.    0.011]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99998038]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 9:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.598 1.    0.766 0.996 0.    1.    0.98  0.999 0.972 0.    0.    0.023\n",
      " 0.997 0.002 0.018 1.    1.    0.999 1.    0.015]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999012]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 10:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.54  1.    0.681 0.998 0.    1.    0.993 0.999 0.951 0.    0.    0.01\n",
      " 0.999 0.    0.019 1.    1.    0.999 1.    0.028]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999502]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 11:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.389 1.    0.571 0.996 0.    1.    0.995 0.998 0.923 0.    0.    0.007\n",
      " 0.999 0.    0.023 1.    1.    0.999 1.    0.013]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999636]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 12:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.339 1.    0.502 0.992 0.    1.    0.986 1.    0.934 0.    0.    0.01\n",
      " 0.998 0.    0.018 1.    1.    0.999 1.    0.008]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999650]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 13:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.319 1.    0.407 0.989 0.    1.    0.99  1.    0.936 0.    0.    0.008\n",
      " 0.999 0.    0.026 1.    1.    0.999 1.    0.005]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999850]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 14:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.354 1.    0.253 0.998 0.    1.    0.99  1.    0.984 0.    0.    0.003\n",
      " 0.998 0.    0.025 1.    1.    0.999 1.    0.004]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999811]\n",
      "AUC-ROC: 1.000\n",
      "\n",
      "Layer 15:\n",
      "True labels: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "Predicted probabilities: [0.399 1.    0.138 0.999 0.    1.    0.99  1.    0.991 0.    0.    0.006\n",
      " 0.999 0.    0.024 1.    1.    1.    1.    0.002]\n",
      "Unique true labels: [0 1]\n",
      "Prediction range: [0.000, 0.99999957]\n",
      "AUC-ROC: 1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Calculate AUC-ROC for each layer\n",
    "auc_scores = []\n",
    "for i, probe in enumerate(layer_probes):\n",
    "    # Get probability predictions for positive class\n",
    "    X = probe._preprocess_activations(test_acts[i])\n",
    "    y_proba = probe._model.predict_proba(X)[:, 1]\n",
    "\n",
    "    # Print debugging information\n",
    "    print(f\"\\nLayer {i}:\")\n",
    "    print(\"True labels:\", test_labels)\n",
    "    print(\"Predicted probabilities:\", y_proba.round(3))\n",
    "\n",
    "    # Verify we have variation in both labels and predictions\n",
    "    print(f\"Unique true labels: {np.unique(test_labels)}\")\n",
    "    print(f\"Prediction range: [{y_proba.min():.3f}, {y_proba.max():.8f}]\")\n",
    "\n",
    "    # Calculate AUC-ROC\n",
    "    try:\n",
    "        auc = roc_auc_score(test_labels, y_proba)\n",
    "        auc_scores.append(auc)\n",
    "        print(f\"AUC-ROC: {auc:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating AUC-ROC: {e}\")\n",
    "        auc_scores.append(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 5 Predictions vs True Labels:\n",
      "    True Label  Predicted Probability\n",
      "1            1                  1.000\n",
      "16           1                  1.000\n",
      "18           1                  1.000\n",
      "5            1                  1.000\n",
      "15           1                  1.000\n",
      "17           1                  0.999\n",
      "3            1                  0.998\n",
      "7            1                  0.998\n",
      "6            1                  0.997\n",
      "12           1                  0.995\n",
      "8            1                  0.956\n",
      "2            0                  0.515\n",
      "0            0                  0.329\n",
      "14           0                  0.003\n",
      "19           0                  0.003\n",
      "11           0                  0.001\n",
      "10           0                  0.000\n",
      "9            0                  0.000\n",
      "4            0                  0.000\n",
      "13           0                  0.000\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for layer 5\n",
    "layer_5_probe = layer_probes[5]\n",
    "X = layer_5_probe._preprocess_activations(test_acts[5])\n",
    "y_proba = layer_5_probe._model.predict_proba(X)[:, 1]\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(\n",
    "    {\"True Label\": test_labels, \"Predicted Probability\": y_proba}\n",
    ").round(3)\n",
    "\n",
    "# Sort by predicted probability for easier analysis\n",
    "results_df = results_df.sort_values(\"Predicted Probability\", ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nLayer 5 Predictions vs True Labels:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
