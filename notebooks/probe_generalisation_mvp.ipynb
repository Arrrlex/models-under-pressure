{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probe Generalisation MVP\n",
    "\n",
    "### Goals:\n",
    "- [x] Choose a layer to train linear probes at\n",
    "  - For now, we're doing layer 5, since that's the earliest layer that got perfect accuracy in the initial probe exploration\n",
    "- [ ] For each category in the 19th Feb dataset, train a linear probe\n",
    "- [ ] Generate a heatmap plot, where the (x, y)-th entry is the accuracy of the probe trained on x data, predicted on y data\n",
    "- [ ] Understand GPU capacity - can we do inference with 70B?\n",
    "\n",
    "### Timeline:\n",
    "- 19/02/25 and 20/02/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from models_under_pressure.probes import (\n",
    "    create_activations,\n",
    ")\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path(\"..\").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "df = pd.read_csv(project_root / \"temp_data/dataset_19_feb.csv\")\n",
    "\n",
    "# Split data by top category\n",
    "categories = {}\n",
    "for category in df[\"top_category\"].unique():\n",
    "    category_df = df[df[\"top_category\"] == category]\n",
    "    categories[category] = {\n",
    "        \"X\": category_df[\"prompt_text\"].tolist(),\n",
    "        \"y\": category_df[\"high_stakes\"].tolist(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 0, Activation Shape: torch.Size([100, 33, 2048])\n",
      "Layer: 1, Activation Shape: torch.Size([100, 33, 2048])\n",
      "Layer: 2, Activation Shape: torch.Size([100, 33, 2048])\n",
      "Layer: 3, Activation Shape: torch.Size([100, 33, 2048])\n",
      "Layer: 4, Activation Shape: torch.Size([100, 33, 2048])\n",
      "Layer: 5, Activation Shape: torch.Size([100, 33, 2048])\n",
      "Layer: 6, Activation Shape: torch.Size([100, 33, 2048])\n",
      "Layer: 7, Activation Shape: torch.Size([100, 33, 2048])\n",
      "Layer: 8, Activation Shape: torch.Size([100, 33, 2048])\n",
      "Layer: 9, Activation Shape: torch.Size([100, 33, 2048])\n",
      "Layer: 10, Activation Shape: torch.Size([100, 33, 2048])\n",
      "Layer: 11, Activation Shape: torch.Size([100, 33, 2048])\n",
      "Layer: 12, Activation Shape: torch.Size([100, 33, 2048])\n",
      "Layer: 13, Activation Shape: torch.Size([100, 33, 2048])\n",
      "Layer: 14, Activation Shape: torch.Size([100, 33, 2048])\n",
      "Layer: 15, Activation Shape: torch.Size([100, 33, 2048])\n",
      "All activations shape: torch.Size([16, 100, 33, 2048])\n",
      "Layer: 0, Activation Shape: torch.Size([100, 34, 2048])\n",
      "Layer: 1, Activation Shape: torch.Size([100, 34, 2048])\n",
      "Layer: 2, Activation Shape: torch.Size([100, 34, 2048])\n",
      "Layer: 3, Activation Shape: torch.Size([100, 34, 2048])\n",
      "Layer: 4, Activation Shape: torch.Size([100, 34, 2048])\n",
      "Layer: 5, Activation Shape: torch.Size([100, 34, 2048])\n",
      "Layer: 6, Activation Shape: torch.Size([100, 34, 2048])\n",
      "Layer: 7, Activation Shape: torch.Size([100, 34, 2048])\n",
      "Layer: 8, Activation Shape: torch.Size([100, 34, 2048])\n",
      "Layer: 9, Activation Shape: torch.Size([100, 34, 2048])\n",
      "Layer: 10, Activation Shape: torch.Size([100, 34, 2048])\n",
      "Layer: 11, Activation Shape: torch.Size([100, 34, 2048])\n",
      "Layer: 12, Activation Shape: torch.Size([100, 34, 2048])\n",
      "Layer: 13, Activation Shape: torch.Size([100, 34, 2048])\n",
      "Layer: 14, Activation Shape: torch.Size([100, 34, 2048])\n",
      "Layer: 15, Activation Shape: torch.Size([100, 34, 2048])\n",
      "All activations shape: torch.Size([16, 100, 34, 2048])\n"
     ]
    }
   ],
   "source": [
    "# Loading model\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "# device = 'cuda:1'\n",
    "device = \"cpu\"\n",
    "\n",
    "# Load the LLaMA-3-1B model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Run the model on each category's data, recording the activations\n",
    "\n",
    "for category in categories:\n",
    "    categories[category][\"acts\"] = create_activations(\n",
    "        model=model, tokenizer=tokenizer, text=categories[category][\"X\"], device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\"C\": 1, \"random_state\": 42, \"fit_intercept\": False}\n",
    "\n",
    "# layer_probes: list[LinearProbe] = Parallel(n_jobs=16)(\n",
    "#     delayed(train_single_layer)(acts, train_labels, model_params) for acts in train_acts\n",
    "# )  # type: ignore\n",
    "\n",
    "# accuracies = [\n",
    "#     compute_accuracy(probe, test_acts[i], test_labels)\n",
    "#     for i, probe in enumerate(layer_probes)\n",
    "# ]\n",
    "\n",
    "# accuracies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
